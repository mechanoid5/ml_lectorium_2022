{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oбучение с подкреплением**\n",
    "\n",
    "Евгений Борисов <esborisov@sevsu.ru>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install gym\n",
    "# !pip3 install gym[atari]\n",
    "# !pip3 install gym[accept-rom-license]\n",
    "# !pip3 install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install ale-py\n",
    "# !ale-import-roms roms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/gym-notebook-wrapper/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install mujoco_py\n",
    "\n",
    "# env_name = 'Ant-v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pacman -S xorg-server-xvfb\n",
    "# !pip3 install pyvirtualdisplay\n",
    "# !pip3 install xvfbwrapper\n",
    "# !pip3 install box2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# блокируем всплывающее окно gym env\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(800,600))\n",
    "display.start()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import gym \n",
    "\n",
    "env_name = 'CartPole-v0'\n",
    "# env_name = 'Pendulum-v1' \n",
    "\n",
    "env = gym.make(env_name)\n",
    "obs = env.reset()\n",
    "\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "plt.grid(False)\n",
    "plt.axis(False)\n",
    "\n",
    "for i in range(100):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "\n",
    "    plt.title(f'step: {i}')\n",
    "    img.set_data(env.render(mode='rgb_array')) \n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "    # if done: break\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.6793083 ,  0.16687025, -8.375089  , -7.9433994 ], dtype=float32),\n",
       " 0.0,\n",
       " True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from keras.layers import Dropout\n",
    "# from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(env):\n",
    "    md = Sequential()\n",
    "    md.add(Dense(256, activation='relu',input_shape=env.observation_space.shape))\n",
    "    md.add(Dense(256, activation='relu'))\n",
    "    md.add(Dense(env.action_space.n))\n",
    "    md.compile(loss='mean_squared_error', optimizer='SGD')\n",
    "    \n",
    "    #md.add(Dense(env.action_space.n, activation='softmax'))\n",
    "    #md.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4))\n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 16:48:03.836359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 16:48:03.864301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 16:48:03.864584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 16:48:03.864949: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-23 16:48:03.865206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 16:48:03.865446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 16:48:03.865572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 16:48:04.208188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 16:48:04.208386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 16:48:04.208501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 16:48:04.208620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4870 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "model = create_model(env)\n",
    "model_target = create_model(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "HISTORY_DEEP = 2000 # глубина истории переходов\n",
    "BATCH_SIZE = 32 # размер батча для обучения модели\n",
    "\n",
    "GAMMA = 0.85 # коэффициент для расчёта оценки reward\n",
    "TAU = 0.125 # определяет различие весов основной и таргет моделей\n",
    "\n",
    "# вероятность использования случайного действия при обучении\n",
    "EPSILON_MAX = 1.0 # в начальном состоянии используем случайный выбор действия\n",
    "EPSILON_MIN = 0.05 # когда модель начала обучаться позволяем ей оценивать действия\n",
    "EPSILON_DECAY = 0.995 # шаг изменения вероятности\n",
    "\n",
    "MAX_EPOCH = 100 # максимальное количество эпох обучения\n",
    "MAX_STEP = 256  # максимальное количество шагов в эпохе (длительность одной игры)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_state(s): return s[np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбор действия\n",
    "def get_action(model,state,eps=EPSILON_MAX): # с вероятностью eps выбираем случайное действие\n",
    "    if np.random.rand()<eps: return env.action_space.sample(), 1\n",
    "    return np.argmax( model.predict( state )[0] ), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replay(model, model_target, history, batch_size=BATCH_SIZE,gamma=GAMMA):\n",
    "\n",
    "    if len(history) < batch_size: return\n",
    "    \n",
    "    samples = [ history[i] for i in np.random.permutation(len(history))[:batch_size] ] \n",
    "\n",
    "    for s in samples:\n",
    "        target = model_target.predict( s['state0'] )\n",
    "        \n",
    "        target[0][ s['act'] ] = s['reward'] \n",
    "        \n",
    "        if s['isdone']:\n",
    "            target[0][ s['act'] ] = s['reward']\n",
    "        else:\n",
    "            target[0][ s['act'] ] = s['reward'] + gamma*max(model_target.predict(s['state1'])[0])\n",
    "            \n",
    "        # model.fit( s['state0'], target, epochs=1, verbose=0)\n",
    "        model.train_on_batch(s['state0'], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_train(model, model_target,tau=TAU):\n",
    "    weights = model.get_weights()\n",
    "    target_weights = model_target.get_weights()\n",
    "    for i in range(len(target_weights)):\n",
    "        target_weights[i] = weights[i] * tau + target_weights[i] * (1. - tau)\n",
    "    model_target.set_weights(target_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 16:48:32.290569: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100 : 36 steps\n",
      "2/100 : 30 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 16:49:49.150557: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/100 : 40 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 16:51:31.859952: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/100 : 16 steps\n",
      "5/100 : 57 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 16:53:45.014972: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/100 : 63 steps\n",
      "7/100 : 31 steps\n",
      "8/100 : 31 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 16:58:25.445852: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-05-23 16:58:42.215438: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-05-23 16:58:56.797570: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/100 : 38 steps\n",
      "10/100 : 54 steps\n",
      "11/100 : 53 steps\n",
      "12/100 : 54 steps\n",
      "13/100 : 53 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 17:07:58.021202: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/100 : 44 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 17:11:00.005773: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/100 : 136 steps\n",
      "16/100 : 74 steps\n",
      "17/100 : 124 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 17:20:36.005784: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-05-23 17:21:28.776502: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-05-23 17:22:06.006754: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-05-23 17:22:08.148416: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/100 : 178 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 17:28:14.640989: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/100 : 63 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 17:29:12.016132: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-05-23 17:30:31.287589: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/100 : 125 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 17:33:43.727638: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-05-23 17:34:35.970326: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = []\n",
    "\n",
    "epsilon = EPSILON_MAX # вероятность использования случайного действия при обучении\n",
    "\n",
    "for e in range(MAX_EPOCH):\n",
    "    # инициализируем среду\n",
    "    state0 = env.reset() \n",
    "    state0 = reshape_state(state0)\n",
    "    for st in range(MAX_STEP):\n",
    "        \n",
    "        # выбираем действие\n",
    "        act, is_act_rand = get_action(model,state0,epsilon)\n",
    "        # применяем действие\n",
    "        state1, reward, done, _ = env.step(act)\n",
    "        state1 = reshape_state(state1)\n",
    "    \n",
    "        # сохраняем историю\n",
    "        history.append({'state0':state0,'state1':state1,'act':act,'reward':reward,'isdone':done})\n",
    "        history = history[-HISTORY_DEEP:] # ограничиваем историю\n",
    "\n",
    "        # коррекция основной модели\n",
    "        replay(model, model_target, history)\n",
    "        \n",
    "        # коррекция таргет модели\n",
    "        target_train(model, model_target)\n",
    "                \n",
    "        if done: break\n",
    "        state0 = state1\n",
    "        epsilon = max(EPSILON_MIN, epsilon*EPSILON_DECAY)\n",
    "                \n",
    "    print('%d/%d : %d steps'%(e+1,MAX_EPOCH,st+1))  \n",
    "    \n",
    "    if st>200: \n",
    "        print('STEP BOUND!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(history)\n",
    "# history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('CartPole-%d.model'%(st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "# model = load_model('CartPole-12.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = env.reset()[np.newaxis,:]\n",
    "# env.render()\n",
    "# #while True:\n",
    "# for t in range(350):    \n",
    "#     a = np.argmax( model.predict(s)[0] )   \n",
    "#     s,r,d,_ = env.step(a)\n",
    "#     s=s[np.newaxis,:]\n",
    "#     env.render()\n",
    "#     if d: \n",
    "#         print(t) \n",
    "#         break\n",
    "# env.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# блокируем всплывающее окно gym env\n",
    "#from pyvirtualdisplay import Display\n",
    "#display = Display(visible=0, size=(800,600))\n",
    "#display.start()\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#from IPython import display\n",
    "#import gym \n",
    "\n",
    "# env_name = 'CartPole-v0'\n",
    "# env_name = 'Pendulum-v1' \n",
    "\n",
    "# env = gym.make(env_name)\n",
    "obs = env.reset()\n",
    "\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "plt.grid(False)\n",
    "plt.axis(False)\n",
    "\n",
    "for i in range(500):\n",
    "    # action = env.action_space.sample()\n",
    "    action = np.argmax( model.predict(obs[np.newaxis,:])[0] )   \n",
    "\n",
    "    obs, reward, done, info = env.step(action)\n",
    "\n",
    "    plt.title(f'step: {i}')\n",
    "    img.set_data(env.render(mode='rgb_array')) \n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "    if done: break\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gym \n",
    "# import matplotlib.pyplot as plt\n",
    "# from IPython import display\n",
    "\n",
    "# env_name = 'BreakoutNoFrameskip-v4'\n",
    "# # env_name = 'SpaceInvaders-v0'\n",
    "\n",
    "# env = gym.make(env_name,render_mode='rgb_array')\n",
    "\n",
    "# obs = env.reset()\n",
    "\n",
    "# img = plt.imshow(env.render(mode='rgb_array')) # only call this once\n",
    "# plt.grid(False)\n",
    "# plt.axis(False)\n",
    "\n",
    "# for i in range(300):\n",
    "#     action = env.action_space.sample()\n",
    "#     obs, reward, done, info = env.step(action)\n",
    "\n",
    "#     plt.title(f'step: {i}')\n",
    "#     img.set_data(env.render(mode='rgb_array')) \n",
    "#     display.display(plt.gcf())\n",
    "#     display.clear_output(wait=True)\n",
    "    \n",
    "#     if done: break\n",
    "        \n",
    "# env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
