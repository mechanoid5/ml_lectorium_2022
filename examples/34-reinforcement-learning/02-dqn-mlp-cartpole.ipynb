{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oбучение с подкреплением**\n",
    "\n",
    "Евгений Борисов <esborisov@sevsu.ru>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install gym\n",
    "# !pip3 install gym[atari]\n",
    "# !pip3 install gym[accept-rom-license]\n",
    "# !pip3 install pygame\n",
    "\n",
    "# https://pypi.org/project/gym-notebook-wrapper/\n",
    "\n",
    "# !pacman -S xorg-server-xvfb\n",
    "# !pip3 install pyvirtualdisplay\n",
    "# !pip3 install xvfbwrapper\n",
    "\n",
    "\n",
    "# !pip3 install box2d\n",
    "\n",
    "# !pip3 install mujoco_py  # env_name = 'Ant-v3'\n",
    "# !pip3 install ale-py     # !ale-import-roms roms/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# блокируем всплывающее окно gym env\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(800,600))\n",
    "display.start()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import gym \n",
    "\n",
    "env_name = 'CartPole-v1'\n",
    "# env_name = 'Pendulum-v1' \n",
    "\n",
    "env = gym.make(env_name)\n",
    "obs = env.reset()\n",
    "\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "plt.grid(False)\n",
    "plt.axis(False)\n",
    "\n",
    "for i in range(100):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "\n",
    "    plt.title(f'step: {i}')\n",
    "    img.set_data(env.render(mode='rgb_array')) \n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "    # if done: break\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs, reward, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from keras.layers import Dropout\n",
    "# from keras.optimizers import SGD\n",
    "\n",
    "def create_model(env):\n",
    "    md = Sequential()\n",
    "    md.add(Dense(32, activation='relu',input_shape=env.observation_space.shape))\n",
    "    md.add(Dense(32, activation='relu'))\n",
    "    md.add(Dense(env.action_space.n))\n",
    "    md.compile(loss='mean_squared_error', optimizer='SGD')\n",
    "    #md.add(Dense(env.action_space.n, activation='softmax'))\n",
    "    #md.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4))\n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 19:56:01.079903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 19:56:01.105263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 19:56:01.105556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 19:56:01.106561: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-29 19:56:01.106818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 19:56:01.107071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 19:56:01.107200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 19:56:01.441225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 19:56:01.441414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 19:56:01.441527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 19:56:01.441620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5369 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2022-05-29 19:56:01.666538: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://c50345fe-68f3-4667-a3e2-b0a4a8046a9f/assets\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "model = create_model(env)\n",
    "# model_target = create_model(env)\n",
    "model_target = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HISTORY_DEEP = 2000 # глубина истории переходов\n",
    "BATCH_SIZE = 32 # размер батча для обучения модели\n",
    "\n",
    "GAMMA = 0.85 # коэффициент для расчёта оценки reward\n",
    "TAU = 0.125 # определяет различие весов основной и таргет моделей\n",
    "\n",
    "# вероятность использования случайного действия при обучении\n",
    "EPSILON_MAX = 1.0 # в начальном состоянии используем случайный выбор действия\n",
    "EPSILON_MIN = 0.05 # когда модель начала обучаться позволяем ей оценивать действия\n",
    "EPSILON_DECAY = 0.995 # шаг изменения вероятности\n",
    "\n",
    "MAX_EPOCH = 100 # максимальное количество эпох обучения\n",
    "MAX_STEP = 200 # максимальное количество шагов в эпохе (длительность одной игры)\n",
    "\n",
    "MIN_STEP = 120\n",
    "\n",
    "MIN_STEP = MIN_STEP if (MIN_STEP<MAX_STEP) else MAX_STEP-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_state(s): return s[np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбор действия\n",
    "def get_action(model,state,eps=EPSILON_MAX): # с вероятностью eps выбираем случайное действие\n",
    "    if np.random.rand()<eps: return env.action_space.sample(), 1\n",
    "    return np.argmax( model.predict( state )[0] ), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replay(model, model_target, history, batch_size=BATCH_SIZE,gamma=GAMMA):\n",
    "\n",
    "    if len(history) < batch_size: return\n",
    "    \n",
    "    samples = [ history[i] for i in np.random.permutation(len(history))[:batch_size] ] \n",
    "\n",
    "    for s in samples:\n",
    "        target = model_target.predict( s['state0'] )\n",
    "        \n",
    "        target[0][ s['act'] ] = s['reward'] \n",
    "        \n",
    "        if s['isdone']:\n",
    "            target[0][ s['act'] ] = s['reward']\n",
    "        else:\n",
    "            target[0][ s['act'] ] = s['reward'] + gamma*max(model_target.predict(s['state1'])[0])\n",
    "            \n",
    "        # model.fit( s['state0'], target, epochs=1, verbose=0)\n",
    "        model.train_on_batch(s['state0'], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_train(model, model_target,tau=TAU):\n",
    "    weights = model.get_weights()\n",
    "    target_weights = model_target.get_weights()\n",
    "    for i in range(len(target_weights)):\n",
    "        target_weights[i] = weights[i] * tau + target_weights[i] * (1. - tau)\n",
    "    model_target.set_weights(target_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100 : 14 steps\n",
      "2/100 : 21 steps\n",
      "3/100 : 15 steps\n",
      "4/100 : 50 steps\n",
      "5/100 : 31 steps\n",
      "6/100 : 53 steps\n",
      "7/100 : 30 steps\n",
      "8/100 : 60 steps\n",
      "9/100 : 61 steps\n",
      "10/100 : 25 steps\n",
      "11/100 : 200 steps\n",
      "STEP BOUND!\n",
      "CPU times: user 18min 46s, sys: 32.1 s, total: 19min 18s\n",
      "Wall time: 17min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = []\n",
    "\n",
    "epsilon = EPSILON_MAX # вероятность использования случайного действия при обучении\n",
    "\n",
    "for e in range(MAX_EPOCH):\n",
    "    # инициализируем среду\n",
    "    state0 = env.reset() \n",
    "    state0 = reshape_state(state0)\n",
    "    for st in range(MAX_STEP):\n",
    "        \n",
    "        # выбираем действие\n",
    "        act, is_act_rand = get_action(model,state0,epsilon)\n",
    "        # применяем действие\n",
    "        state1, reward, done, _ = env.step(act)\n",
    "        state1 = reshape_state(state1)\n",
    "    \n",
    "        # сохраняем историю\n",
    "        history.append({'state0':state0,'state1':state1,'act':act,'reward':reward,'isdone':done})\n",
    "        history = history[-HISTORY_DEEP:] # ограничиваем историю\n",
    "\n",
    "        # коррекция основной модели\n",
    "        replay(model, model_target, history)\n",
    "        \n",
    "        # коррекция таргет модели\n",
    "        target_train(model, model_target)\n",
    "                \n",
    "        if done: break\n",
    "        state0 = state1\n",
    "        epsilon = max(EPSILON_MIN, epsilon*EPSILON_DECAY)\n",
    "                \n",
    "    print('%d/%d : %d steps'%(e+1,MAX_EPOCH,st+1))  \n",
    "    \n",
    "    if st>MIN_STEP: \n",
    "        print('STEP BOUND!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CartPole-199.model/assets\n"
     ]
    }
   ],
   "source": [
    "model_name = f'CartPole-{st}.model'\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'CartPole-170.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model_ = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# блокируем всплывающее окно gym env\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(800,600))\n",
    "display.start()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import gym \n",
    "\n",
    "# env_name = 'CartPole-v1'\n",
    "# env_name = 'Pendulum-v1' \n",
    "\n",
    "env = gym.make(env_name)\n",
    "obs = env.reset()\n",
    "\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "plt.grid(False)\n",
    "plt.axis(False)\n",
    "\n",
    "for i in range(100):\n",
    "    # action = env.action_space.sample()\n",
    "    action = np.argmax( model_.predict(obs[np.newaxis,:])[0] )   \n",
    "    obs, reward, done, info = env.step(action)\n",
    "\n",
    "    plt.title(f'step: {i}')\n",
    "    img.set_data(env.render(mode='rgb_array')) \n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "    if done: break\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # блокируем всплывающее окно gym env\n",
    "# from pyvirtualdisplay import Display\n",
    "# display = Display(visible=0, size=(800,600))\n",
    "# display.start()\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from IPython import display\n",
    "# import gym \n",
    "\n",
    "# # env_name = 'Pendulum-v1' \n",
    "# # env_name = 'BreakoutNoFrameskip-v4'\n",
    "# env_name = 'SpaceInvaders-v0'\n",
    "\n",
    "# env = gym.make(env_name)\n",
    "# obs = env.reset()\n",
    "\n",
    "# img = plt.imshow(env.render(mode='rgb_array'))\n",
    "# plt.grid(False)\n",
    "# plt.axis(False)\n",
    "\n",
    "# for i in range(100):\n",
    "#     action = env.action_space.sample()\n",
    "#     obs, reward, done, info = env.step(action)\n",
    "\n",
    "#     plt.title(f'step: {i}')\n",
    "#     img.set_data(env.render(mode='rgb_array')) \n",
    "#     display.display(plt.gcf())\n",
    "#     display.clear_output(wait=True)\n",
    "    \n",
    "#     if done: break\n",
    "        \n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.9\n",
      "IPython version      : 8.0.1\n",
      "\n",
      "tensorflow: 2.8.0\n",
      "numpy     : 1.22.2\n",
      "gym       : 0.23.1\n",
      "IPython   : 8.0.1\n",
      "matplotlib: 3.5.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install watermark\n",
    "# Python package versions used\n",
    "%load_ext watermark\n",
    "%watermark --python\n",
    "%watermark --iversions\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
