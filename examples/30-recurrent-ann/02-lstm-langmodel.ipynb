{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**рекуррентная нейронная сеть LSTM**\n",
    "\n",
    "Евгений Борисов <esborisov@sevsu.ru>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random as rng\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=2) # вывод на печать чисел до 2 знака\n",
    "# pd.options.display.max_colwidth=200 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Праздник состоялся, несмотря ни на какие недоумения прошедшего \"Шпигулинского\" дня. Я думаю, что если бы даже Лембке умер в ту самую ночь, то праздник все-таки бы состоялся на утро, - до того много соединяла с ним какого-то особенного значения Юлия Михайловна. Увы, она до последней минуты находилась в ослеплении и не понимала настроения общества. Никто под конец не верил, что торжественный день пройдет без какого-нибудь колоссального приключения, без \"развязки\", как выражались иные, заранее потирая руки. Многие, правда, старались принять самый нахмуренный и политический вид; но вообще говоря, непомерно веселит русского человека всякая общественная скандальная суматоха. Правда, было у нас нечто и весьма посерьезнее одной лишь жажды скандала: было всеобщее раздражение, что-то неутолимо злобное; казалось, всем все надоело ужасно. Воцарился какой-то всеобщий сбивчивый цинизм, цинизм через силу, как бы с натуги.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/text/dostoevsky-besy.txt','rt',encoding='utf-8') as f: text = f.read()    \n",
    "print(len(text))    \n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.lower()[:-1]\n",
    "abc = { c:i for i,c in enumerate(sorted(set(text))) } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'праздник состоялся, несмотря ни на какие недоумения прошедшего \"шпигулинского\" дня. я думаю, что если бы даже лембке умер в ту самую ночь, то праздник все-таки бы состоялся на утро, - до того много соединяла с ним какого-то особенного значения юлия михайловна. увы, она до последней минуты находилась в ослеплении и не понимала настроения общества. никто под конец не верил, что торжественный день пройдет без какого-нибудь колоссального приключения, без \"развязки\", как выражались иные, заранее потирая руки. многие, правда, старались принять самый нахмуренный и политический вид; но вообще говоря, непомерно веселит русского человека всякая общественная скандальная суматоха. правда, было у нас нечто и весьма посерьезнее одной лишь жажды скандала: было всеобщее раздражение, что-то неутолимо злобное; казалось, всем все надоело ужасно. воцарился какой-то всеобщий сбивчивый цинизм, цинизм через силу, как бы с натуги.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w=15\n",
    "\n",
    "# symbol_seq = [ [ text[i:i+w],text[i+w] ] for i in range(len(text)-w) ]\n",
    "# symbol_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eye = np.eye(max(abc.values())+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# re.split(r'[.,]',text)\n",
    "# text.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoded = np.array(list( map( lambda c: abc[c],list(text) ) ))\n",
    "text_encoded = np.eye(max(abc.values())+1,dtype=np.float32)[text_encoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 125\n",
    "text_encoded_seq = [ \n",
    "    [ text_encoded[i:i+w],text_encoded[i+w] ] \n",
    "    for i in range(len(text_encoded)-w) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((795, 125, 36), (795, 36))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.stack([ s[0] for s in text_encoded_seq ])\n",
    "y_train = np.stack([ s[1] for s in text_encoded_seq ])\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        #self.rcl0 = nn.GRU(input_dim, hid_dim,)\n",
    "        self.rcl0 = nn.LSTM(input_dim, hid_dim,)\n",
    "        self.dense0 = nn.Linear(hid_dim,input_dim) \n",
    "        self.softmax0 = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # o, s = self.rcl0(x)\n",
    "        o, _ = self.rcl0(x)\n",
    "        o = self.dense0(o[:,-1,:])\n",
    "        o = self.softmax0(o)\n",
    "        return o\n",
    "        #return o[:,-1,:],s[:,-1,:]\n",
    "        \n",
    "    def predict(self, x):    \n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_train.shape[-1],1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.Tensor(input_seq[[1],:,:])\n",
    "# with torch.set_grad_enabled(False): \n",
    "#     y = model.forward(x)    \n",
    "#     #y,s = model.forward(x)\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "#criterion = nn.BCELoss() # ф-ция потери\n",
    "criterion = nn.MSELoss() # ф-ция потери\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3) # метод оптимизации ф-ции потери"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# используем GPU если есть\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.set_grad_enabled(False):\n",
    "    loss = criterion( \n",
    "            torch.Tensor(y_train).to(device), \n",
    "            model.predict( torch.Tensor(X_train).to(device) ) \n",
    "        ).cpu().numpy().flatten()[0]\n",
    "    \n",
    "loss_history = [ loss ] # начальное значение ф-ции потери"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def accuracy(x,y):\n",
    "    with torch.set_grad_enabled(False):\n",
    "        o = model.predict(torch.Tensor(x).to(device)).cpu().numpy()\n",
    "    return accuracy_score(np.argmax(y,axis=1),np.argmax(o,axis=1))\n",
    "\n",
    "acc_history = [ accuracy(X_train,y_train) ] # начальное значение погрешности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# пакуем данные в формат Torch\n",
    "dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 381/512 [07:32<02:35,  1.19s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from tqdm import tqdm # рисует прогрессбар\n",
    "from torch.utils.data import DataLoader # генератор батчей\n",
    "\n",
    "n_epoch = 512 # количество эпох обучения\n",
    "acc_min = .98 # порог минимально допустимой погрешности модели\n",
    "\n",
    "for i in tqdm(range(n_epoch)): \n",
    "    \n",
    "    for x,y in DataLoader(dataset, batch_size=len(y_train)//3, shuffle=True): # получаем батч учебных примеров\n",
    "        out = model.forward(x.to(device)) # считаем выход модели\n",
    "        loss = criterion( y.to(device),out ) # вычисляем значение ф-ции потери\n",
    "        loss_history.append(loss.item()) # дополняем историю изменения значений ф-ции потери\n",
    "        optimizer.zero_grad() # очищаем предыдущее значение градиента\n",
    "        loss.backward()  # вычисляем текущее значение градиента ф-ции потери\n",
    "        optimizer.step() # корректируем параметры модели\n",
    "        \n",
    "    acc_history.append( accuracy(X_train,y_train) ) #значение погрешности\n",
    "    if acc_history[-1] > acc_min: # проверяем достижение минимального порога погрешности модели\n",
    "        print('step %i/%i: loss %.03f, acc threshold %.03f reached\\n'%(i+1,n_epoch,loss_history[-1],acc_min))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# история изменения значений ф-ции потери\n",
    "plt.plot(loss_history,label='min loss=%.3f'%(min(loss_history)))\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# история изменения значений погрешности модели\n",
    "plt.plot(acc_history,label='max acc=%.3f'%(max(acc_history)),c='r')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.set_grad_enabled(False):\n",
    "    o = model.predict(torch.Tensor(X_train).to(device)).cpu().numpy()\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(o,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
